#!/usr/bin/env python3
"""
Death data preprocessing script for DiePlease addon
Converts db.json into a single Lua table file containing all maps
"""

import json
import os
from collections import defaultdict

def generate_heatmap_file(map_data, map_max_deaths, output_file, grid_size, total_deaths):
    """Generate a single heatmap.lua file containing all map data"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('-- Death heatmap data for all maps\n')
        f.write(f'-- Total death records: {total_deaths}\n')
        f.write(f'-- Total maps: {len(map_data)}\n')
        f.write('-- Auto-generated by process_deaths.py\n\n')

        f.write('if not MapData then MapData = {} end\n\n')
        f.write('MapData = {\n')

        map_ids = sorted(map_data.keys())
        for i, map_id in enumerate(map_ids):
            f.write(f'    [{map_id}] = {{\n')
            f.write(f'        gridSize = {grid_size},\n')
            f.write(f'        maxDeaths = {map_max_deaths[map_id]},\n')
            f.write(f'        grid = {{\n')

            grid = map_data[map_id]
            if grid:
                x_coords = sorted(grid.keys())
                for j, x in enumerate(x_coords):
                    f.write(f'            [{x}] = {{')
                    y_coords = sorted(grid[x].keys())
                    for k, y in enumerate(y_coords):
                        count = grid[x][y]
                        f.write(f'[{y}] = {count}')
                        if k < len(y_coords) - 1:
                            f.write(', ')
                    f.write('}')
                    if j < len(x_coords) - 1:
                        f.write(',\n')
                    else:
                        f.write('\n')

            f.write('        }')
            if i < len(map_ids) - 1:
                f.write('},\n')
            else:
                f.write('}\n')

        f.write('}\n')

def process_death_data(json_file, output_dir):
    """Process death data and generate a single Lua file with all maps"""

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    # Load death data
    print("Loading death data...")
    with open(json_file, 'r', encoding='utf-8') as f:
        death_data = json.load(f)

    print(f"Loaded {len(death_data)} death records")

    # Aggregate deaths by map and grid cells
    map_data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
    map_max_deaths = defaultdict(int)
    grid_size = 50
    total_deaths = 0

    print("Aggregating deaths by grid cells...")
    for key, death in death_data.items():
        map_id = death.get('map_id')
        if not map_id:
            continue

        pos = death.get('map_pos', [])
        if len(pos) < 2:
            continue

        x, y = pos
        grid_x = int(x / grid_size)
        grid_y = int(y / grid_size)

        # Increment death count for this grid cell
        map_data[map_id][grid_x][grid_y] += 1
        map_max_deaths[map_id] = max(map_max_deaths[map_id], map_data[map_id][grid_x][grid_y])
        total_deaths += 1

    # Generate single heatmap file
    output_file = os.path.join(output_dir, 'heatmap.lua')
    print(f"Generating {output_file}...")

    generate_heatmap_file(map_data, map_max_deaths, output_file, grid_size, total_deaths)

    # Print statistics
    print(f"\nComplete! Generated heatmap.lua with:")
    print(f"  - {total_deaths} total death records")
    print(f"  - {len(map_data)} maps")
    print(f"  - Grid size: {grid_size}x{grid_size}")

    # Print map details
    for map_id in sorted(map_data.keys()):
        death_count = sum(sum(row.values()) for row in map_data[map_id].values())
        print(f"    Map {map_id}: {death_count} deaths, max density: {map_max_deaths[map_id]}")

if __name__ == "__main__":
    # Configuration
    json_file = "db.json"
    output_dir = "Data"

    # Process the data
    process_death_data(json_file, output_dir)